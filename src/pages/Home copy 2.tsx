/* eslint-disable no-empty-pattern */
/* eslint-disable @typescript-eslint/no-unused-vars */
import { useState, useEffect, useRef } from 'react';
import Chat, { MessageProps, useMessages, Bubble, Think, TypingBubble, RecorderHandle } from '@chatui/core';
import { Welcome } from '@ant-design/x';
import Slider from 'react-slick';
import { Button, message } from 'antd';
import 'slick-carousel/slick/slick.css';
import 'slick-carousel/slick/slick-theme.css';
import '@chatui/core/dist/index.css';
import './../styles/chatui-theme.css';
import { marked } from 'marked';
import OpenAI from "openai";
import { startSpeechRecognition, speak } from '../utils/speech';

const openai = new OpenAI({
  baseURL: 'https://api.deepseek.com',
  apiKey: 'sk-6080deca60b746ee9f703dd8bbe32cb2', dangerouslyAllowBrowser: true // æ›¿æ¢ä¸ºä½ çš„ API Key
});

const useIsMobile = () => {
  const [isMobile, setIsMobile] = useState(window.innerWidth <= 768);

  useEffect(() => {
    const handleResize = () => {
      setIsMobile(window.innerWidth <= 768);
    };
    window.addEventListener('resize', handleResize);
    return () => window.removeEventListener('resize', handleResize);
  }, []);

  return isMobile;
};

const questionSuggestions = [
  { id: 1, text: 'äº”ä¸€å‡æœŸ', icon: 'ğŸ”¥' },
  { id: 2, text: 'ä¸–ç•Œè¯»ä¹¦æ—¥', icon: 'ğŸ”¥' },
  { id: 3, text: 'å¦‚ä½•åŠç†å¤ªåŸæ–‡æ—…ä¸€å¡é€šï¼Ÿ', },
  { id: 4, text: 'å…¬äº¤å¡å¦‚ä½•å……å€¼ï¼Ÿ', },
  { id: 5, text: 'å¦‚ä½•é¢„çº¦æŒ‚å·ï¼Ÿ', },
  { id: 6, text: 'å…¬ç§¯é‡‘å¦‚ä½•æå–ï¼Ÿ', icon: 'ğŸ”¥' },
];

const sliderSettings = {
  dots: false,
  infinite: true,
  speed: 2000,
  slidesToShow: 3,
  slidesToScroll: 1,
  autoplay: true,
  autoplaySpeed: 1000,
  rows: 2,
  responsive: [
    {
      breakpoint: 768,
      settings: {
        slidesToShow: 2,
        rows: 2
      }
    }
  ]
};

type ChatMessage = {
  role: 'system' | 'user' | 'assistant';
  content: string;
};

const Home = () => {
  const isMobile = useIsMobile();
  const { messages, appendMsg, updateMsg } = useMessages([]);
  const MAX_HISTORY = 20; // æœ€å¤§å¯¹è¯è½®æ•°
  const [chatHistory, setChatHistory] = useState<ChatMessage[]>([
    { role: 'system', content: 'ä½ æ˜¯é”¦å°ç»£ï¼Œå¤ªåŸå¹¿æ’­ç”µè§†å°æ‰“é€ çš„æ™ºèƒ½åŠ©æ‰‹ã€‚åœ¨å›ç­”é—®é¢˜çš„æ—¶å€™ï¼Œè¦åšåˆ°çœŸå®æ€§ï¼Œè¦æœ‰æ‰€ä¾æ®ï¼Œå¹¶ç»™å‡ºä¾æ®é“¾æ¥ã€‚è€Œä¸”ä¿æŒå®æ—¶æ€§ã€‚' }
  ]);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [enableVoice,] = useState(false);
  const [, setIsRecording] = useState(false);

  // const [enableVoice, setEnableVoice] = useState(false);
  // const [isRecording, setIsRecording] = useState(false);
  const recorderRef = useRef<RecorderHandle>(null!);

  async function handleSend(type: string, val: string) {
    if (type === 'text' && val.trim()) {
      const newHistory: ChatMessage[] = [...chatHistory, { role: 'user' as const, content: val }];
      if (newHistory.length > MAX_HISTORY * 2 + 1) {
        newHistory.splice(1, 2);
      }
      setChatHistory(newHistory);

      appendMsg({
        type: 'text',
        content: { text: val },
        position: 'right',
      });

      const thinkingMsg = appendMsg({
        type: 'thinking',
        content: { text: 'è®©æˆ‘æ€è€ƒä¸€ä¸‹...' },
        position: 'left',
      });

      try {
        const completion = await openai.chat.completions.create({
          messages: chatHistory.concat({ role: 'user', content: val }),
          model: "deepseek-reasoner",
          stream: true,
        });

        let streamContent = '';
        let streamReasoningContent = '';
        const streamMsg = appendMsg({
          type: 'stream',
          content: { text: '' },
          position: 'left',
        });

        for await (const chunk of completion) {
          const content = chunk.choices[0]?.delta?.content || '';
          const reasoningContent = (chunk.choices[0]?.delta as { reasoning_content?: string })?.reasoning_content || '';

          streamContent += content;

          streamReasoningContent += reasoningContent;
          if (streamReasoningContent) {
            updateMsg(thinkingMsg, {
              type: 'thinking',
              content: { text: `è®©æˆ‘æ€è€ƒä¸€ä¸‹...\n\n${streamReasoningContent}` },
            });
          }

          updateMsg(streamMsg, {
            type: 'stream',
            content: { text: streamContent },
          });
        }

        if (streamContent) {
          setChatHistory(prev => [...prev, {
            role: 'assistant',
            content: streamContent
          }]);

          if (enableVoice && !isSpeaking) {
            try {
              setIsSpeaking(true);
              await speak(streamContent);
            } catch (error) {
              console.error('è¯­éŸ³åˆæˆé”™è¯¯:', error);
            } finally {
              setIsSpeaking(false);
            }
          }
        }

      } catch (error) {
        console.error('API Error:', error);
        updateMsg(thinkingMsg, {
          type: 'text',
          content: { text: 'æŠ±æ­‰ï¼ŒæœåŠ¡å™¨å‡ºç°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚' },
        });
      }
    }
  }

  // const handleRecordStart = () => {
  //   setIsRecording(true);
  //   message.info('å¼€å§‹å½•éŸ³...');
  // };
  async function requestMicrophonePermission(): Promise<boolean> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      stream.getTracks().forEach(track => track.stop()); // é©¬ä¸Šå…³é—­
      return true;
    } catch (err) {
      console.error('éº¦å…‹é£æƒé™è¢«æ‹’ç»', err);
      message.error('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ‰‹åŠ¨å¼€å¯æƒé™');
      return false;
    }
  }
  const handleRecordStart = async () => {
    const allowed = await requestMicrophonePermission();
    if (!allowed) return;
  
    setIsRecording(true);
    message.info('å¼€å§‹å½•éŸ³...');
  };

  const handleRecordEnd = async () => {
    setIsRecording(false);
    message.loading('æ­£åœ¨è¯†åˆ«è¯­éŸ³...');
    
    try {
      const transcript = await startSpeechRecognition();
      if (transcript) {
        message.success('è¯­éŸ³è¯†åˆ«æˆåŠŸ');
        handleSend('text', transcript);
      }
    } catch (error: any) {
      console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', error);
      // é”™è¯¯æ¶ˆæ¯å·²ç»åœ¨ startSpeechRecognition ä¸­å¤„ç†
    } finally {
      message.destroy(); // æ¸…é™¤ loading æ¶ˆæ¯
    }
  };

  const handleRecordCancel = () => {
    setIsRecording(false);
    message.info('å·²å–æ¶ˆå½•éŸ³');
  };

  const renderMarkdown = (content: string) => marked.parse(content) as string;

  function renderMessageContent(msg: MessageProps) {
    const { type, content } = msg;

    switch (type) {
      case 'text':
        return <Bubble data-animation='fadeInUp' content={content.text} />;
      case 'stream':
        return (
          <TypingBubble
            data-animation='fadeInUp'
            content={content.text}
            messageRender={renderMarkdown}
            isRichText
            options={{ step: [1, 4], interval: 50 }}
          />
        );
      case 'image':
        return (
          <Bubble type="image">
            <img src={content.picUrl} alt="" />
          </Bubble>
        );
      case 'thinking':
        return (
          <Bubble>
            <Think isDone={false}>
              <p>{content.text}</p>
            </Think>
          </Bubble>
        );
      default:
        return null;
    }
  }

  function handleQuickReplyClick(item: { name: string }) {
    handleSend('text', item.name);
  }

  return (
    <div style={{
      height: '100vh',
      display: 'flex',
      flexDirection: 'column',
      overflow: 'hidden',
      background: 'linear-gradient(97deg, #f2f9fe 0%, #f7f3ff 100%)',
      padding: isMobile ? '16px' : '24px',
    }}>
      <Welcome
        style={{
          borderRadius: '16px',
        }}
        variant="borderless"
        icon="https://ai-tool-1255431317.cos.ap-beijing.myqcloud.com/202504291722214.gif"
        title={<div style={{ fontSize: isMobile ? '20px' : '24px' }}>ä½ å¥½ï¼æˆ‘æ˜¯é”¦å°ç»£</div>}
        description={
          <div style={{ fontSize: isMobile ? '14px' : '16px' }}>
            å¤ªåŸå¹¿æ’­ç”µè§†å°æ‰“é€ çš„æ™ºèƒ½åŠ©æ‰‹é”¦å°ç»£ï¼Œå…·å¤‡çŸ¥è¯†åº“ç®¡ç†ã€å¤§è¯­è¨€æ¨¡å‹å¯¹è¯ã€æ™ºèƒ½ä½“æç¤ºè¯ã€ç”Ÿæ´»æœåŠ¡åŠ©æ‰‹ç­‰åŠŸèƒ½~
          </div>
        }
      />

      <div style={{
        margin: isMobile ? '0px 0' : '16px 0',
        padding: '16px',
        borderRadius: '16px',
      }}>
        <Slider {...sliderSettings}>
          {questionSuggestions.map((question) => (
            <div
              key={question.id}
              style={{
                padding: '8px',
                display: 'inline-block',
                width: '100%',
                boxSizing: 'border-box',
              }}
            >
              <Button
                type="default"
                icon={question.icon}
                style={{
                  width: '90%',
                  minHeight: isMobile ? '60px' : '72px',
                  height: 'auto',
                  borderRadius: '12px',
                  padding: '12px 20px',
                  border: '1px solid rgba(22,119,255,0.1)',
                  background: 'rgba(255,255,255,0.9)',
                  fontSize: isMobile ? '14px' : '16px',
                  display: 'flex',
                  alignItems: 'center',
                  justifyContent: 'flex-start',
                  gap: '12px',
                  overflow: 'hidden',
                  textOverflow: 'ellipsis',
                  margin: '0 auto',
                  wordBreak: 'break-word',
                  whiteSpace: 'pre-wrap',
                  lineHeight: '1.4',
                }}
                onClick={() => handleSend('text', question.text)}
              >
                {question.text}
              </Button>
            </div>
          ))}
        </Slider>
      </div>

      <div style={{
        flex: 1,
        position: 'relative',
        overflow: 'hidden',
        background: 'rgba(255, 255, 255, 0.6)',
        borderRadius: '16px',
        marginBottom: '16px',
      }}>
        <Chat
          recorder={{
            canRecord: true,
            volume: 100,
            onStart: handleRecordStart,
            onEnd: handleRecordEnd,
            onCancel: handleRecordCancel,
            ref: recorderRef
          }}
          wideBreakpoint="800px"
          messages={messages}
          renderMessageContent={renderMessageContent}
          onSend={handleSend}
          onQuickReplyClick={handleQuickReplyClick}
          onImageSend={() => Promise.resolve()}
        />
      </div>
      {/* <VoiceSwitch /> */}
    </div>
  );
}
export default Home;    