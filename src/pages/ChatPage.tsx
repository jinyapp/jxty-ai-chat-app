import { useState, useEffect, useRef } from 'react'
import { useNavigate, useLocation } from 'react-router-dom'
import { Bubble, Sender, Think, Welcome } from '@ant-design/x'
import XMarkdown from '@ant-design/x-markdown'
import type { BubbleListRef, BubbleItemType } from '@ant-design/x/es/bubble/interface'
import Slider from 'react-slick'
import { Space, Spin, Button, message, Progress, Typography } from 'antd'
import 'slick-carousel/slick/slick.css'
import 'slick-carousel/slick/slick-theme.css'
import './../styles/chat.css'
import './../styles/voice.css'
import { authFetch, ensureAuth } from '../utils/auth'
import { post } from '../utils/request'

import { 
  OpenAIOutlined, 
  AudioOutlined, 
  FormOutlined, 
  ArrowLeftOutlined,
  StopOutlined 
} from '@ant-design/icons'

const { Text } = Typography

const VOICE_ENABLED = (() => {
  const v = String(import.meta.env.VITE_APP_ENABLE_VOICE ?? 'true').toLowerCase()
  return v === 'true' || v === '1' || v === 'on'
})()

// æµå¼è¯­éŸ³è¯†åˆ« Hook
function useStreamVoiceInput(onResult: (text: string) => Promise<void>) {
  const [recording, setRecording] = useState(false)
  const [processing, setProcessing] = useState(false)
  const [interimText, setInterimText] = useState('')
  const [audioLevel, setAudioLevel] = useState(0)
  
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const wsRef = useRef<WebSocket | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null)
  const recordTimerRef = useRef<NodeJS.Timeout | null>(null)
  const animationFrameRef = useRef<number | null>(null)

  const speechSupported = !!navigator.mediaDevices?.getUserMedia && typeof MediaRecorder !== 'undefined'

  // éŸ³é¢‘çº§åˆ«æ£€æµ‹
  const updateAudioLevel = () => {
    if (!analyserRef.current || !recording) return
    
    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)
    analyserRef.current.getByteFrequencyData(dataArray)
    
    const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length
    const normalizedLevel = average / 255
    setAudioLevel(normalizedLevel)
    
    // VAD - è¯­éŸ³æ´»åŠ¨æ£€æµ‹
    const isVoiceActive = normalizedLevel > 0.02
    
    if (isVoiceActive) {
      // æ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ¸…é™¤é™éŸ³è®¡æ—¶å™¨
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current)
        silenceTimerRef.current = null
      }
    } else if (recording && !silenceTimerRef.current) {
      // å¼€å§‹é™éŸ³è®¡æ—¶ - 3ç§’æ— å£°éŸ³è‡ªåŠ¨åœæ­¢
      silenceTimerRef.current = setTimeout(() => {
        console.log('æ£€æµ‹åˆ°é™éŸ³ï¼Œè‡ªåŠ¨åœæ­¢å½•åˆ¶')
        stopRecording()
      }, 3000)
    }
    
    if (recording) {
      animationFrameRef.current = requestAnimationFrame(updateAudioLevel)
    }
  }

  // åˆå§‹åŒ– WebSocket è¿æ¥
  const initWebSocket = () => {
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:'
    const wsUrl = `${protocol}//${window.location.host}/ws/speech`
    wsRef.current = new WebSocket(wsUrl)
    
    wsRef.current.onopen = () => {
      console.log('è¯­éŸ³è¯†åˆ« WebSocket è¿æ¥æˆåŠŸ')
      // å‘é€å¼€å§‹ä¿¡å·
      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({ type: 'start' }))
      }
    }
    
    wsRef.current.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data)
        console.log('æ”¶åˆ°è¯­éŸ³è¯†åˆ«ç»“æœ:', data)
        
        if (data.type === 'interim') {
          // å®æ—¶è¯†åˆ«ç»“æœ
          setInterimText(data.text || '')
        } else if (data.type === 'final') {
          // æœ€ç»ˆè¯†åˆ«ç»“æœ
          const finalText = data.text || ''
          if (finalText.trim()) {
            onResult(finalText)
          }
          setInterimText('')
          setProcessing(false)
        } else if (data.type === 'error') {
          console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', data.message)
          message.error(data.message || 'è¯­éŸ³è¯†åˆ«å¤±è´¥')
          setProcessing(false)
        }
      } catch (error) {
        console.error('è§£æè¯­éŸ³è¯†åˆ«æ¶ˆæ¯å¤±è´¥:', error)
      }
    }
    
    wsRef.current.onerror = (error) => {
      console.error('è¯­éŸ³è¯†åˆ« WebSocket é”™è¯¯:', error)
      message.error('è¯­éŸ³è¯†åˆ«è¿æ¥å¤±è´¥')
      setProcessing(false)
    }
    
    wsRef.current.onclose = () => {
      console.log('è¯­éŸ³è¯†åˆ« WebSocket è¿æ¥å…³é—­')
      setProcessing(false)
    }
  }

  // å¼€å§‹å½•åˆ¶
  const startRecording = async () => {
    if (!speechSupported) {
      message.error('è®¾å¤‡ä¸æ”¯æŒè¯­éŸ³å½•åˆ¶')
      return
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })
      
      mediaStreamRef.current = stream
      
      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡ç”¨äºåˆ†æ
      const AC = (window as unknown as { webkitAudioContext?: typeof AudioContext }).webkitAudioContext || AudioContext
      audioContextRef.current = new AC({ sampleRate: 16000 })
      const source = audioContextRef.current.createMediaStreamSource(stream)
      
      analyserRef.current = audioContextRef.current.createAnalyser()
      analyserRef.current.fftSize = 256
      source.connect(analyserRef.current)
      
      // åˆå§‹åŒ– WebSocket
      initWebSocket()
      
      // åˆ›å»º MediaRecorder
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
        ? 'audio/webm;codecs=opus' 
        : 'audio/webm'
      
      mediaRecorderRef.current = new MediaRecorder(stream, { mimeType })
      
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0 && wsRef.current?.readyState === WebSocket.OPEN) {
          // å‘é€éŸ³é¢‘æ•°æ®åˆ° WebSocket
          wsRef.current.send(event.data)
        }
      }
      
      mediaRecorderRef.current.start(200) // æ¯200mså‘é€ä¸€æ¬¡æ•°æ®
      setRecording(true)
      
      // å¼€å§‹éŸ³é¢‘çº§åˆ«æ£€æµ‹
      updateAudioLevel()
      
      // è®¾ç½®æœ€å¤§å½•åˆ¶æ—¶é—´ 60ç§’
      recordTimerRef.current = setTimeout(() => {
        stopRecording()
        message.warning('å½•åˆ¶æ—¶é—´è¶…è¿‡60ç§’ï¼Œè‡ªåŠ¨åœæ­¢')
      }, 60000)
      
    } catch (error) {
      console.error('å¼€å§‹å½•åˆ¶å¤±è´¥:', error)
      message.error('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®')
    }
  }

  // åœæ­¢å½•åˆ¶
  const stopRecording = () => {
    setRecording(false)
    setProcessing(true)
    
    // æ¸…ç†è®¡æ—¶å™¨
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current)
      silenceTimerRef.current = null
    }
    
    if (recordTimerRef.current) {
      clearTimeout(recordTimerRef.current)
      recordTimerRef.current = null
    }

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
      animationFrameRef.current = null
    }
    
    // åœæ­¢å½•åˆ¶
    if (mediaRecorderRef.current?.state === 'recording') {
      mediaRecorderRef.current.stop()
    }
    
    // å‘é€åœæ­¢ä¿¡å·åˆ° WebSocket
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: 'stop' }))
    }
    
    // åœæ­¢åª’ä½“æµ
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop())
      mediaStreamRef.current = null
    }
    
    // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
    }
    
    // å»¶è¿Ÿå…³é—­ WebSocketï¼Œç­‰å¾…æœ€ç»ˆç»“æœ
    setTimeout(() => {
      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.close()
      }
      setAudioLevel(0)
    }, 2000)
  }

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      if (recording) {
        stopRecording()
      }
    }
  }, [])

  return {
    recording,
    processing,
    interimText,
    audioLevel,
    speechSupported,
    startRecording,
    stopRecording
  }
}

// ä¼ ç»Ÿè¯­éŸ³è¯†åˆ« Hook (å¤‡ç”¨)
function useVoiceInput(onResult: (text: string) => Promise<void>) {
  const [recording, setRecording] = useState(false)
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const recordChunksRef = useRef<BlobPart[]>([])
  const recordMimeTypeRef = useRef<string>('')

  const speechSupported = !!(window.MediaRecorder && navigator.mediaDevices?.getUserMedia)

  function getSupportedMimeType(): string {
    const types = ['audio/webm;codecs=opus','audio/webm','audio/ogg;codecs=opus','audio/ogg','audio/wav']
    for (const t of types) { 
      if (MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported(t)) return t 
    }
    return ''
  }

  function mimeToExt(mime: string): string {
    if (!mime) return 'webm'
    if (mime.includes('webm')) return 'webm'
    if (mime.includes('ogg')) return 'ogg'
    if (mime.includes('wav')) return 'wav'
    if (mime.includes('mp3')) return 'mp3'
    if (mime.includes('m4a')) return 'm4a'
    return 'webm'
  }

  async function start() {
    if (!speechSupported) { 
      message.error('è®¾å¤‡ä¸æ”¯æŒè¯­éŸ³å½•åˆ¶')
      return 
    }
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      mediaStreamRef.current = stream
      const mime = getSupportedMimeType()
      recordMimeTypeRef.current = mime
      const mr = mime ? new MediaRecorder(stream, { mimeType: mime }) : new MediaRecorder(stream)
      mediaRecorderRef.current = mr
      recordChunksRef.current = []
      mr.ondataavailable = (e) => { 
        const d = (e as unknown as BlobEvent).data
        if (d && d.size > 0) recordChunksRef.current.push(d) 
      }
      mr.start()
      setRecording(true)
    } catch (error) {
      message.error('è¯·å…è®¸ä½¿ç”¨éº¦å…‹é£')
      setRecording(false)
    }
  }

  async function stop(): Promise<Blob | null> {
    const mr = mediaRecorderRef.current
    if (!mr) return null
    return new Promise((resolve) => {
      mr.onstop = () => {
        const blob = new Blob(recordChunksRef.current, { type: recordMimeTypeRef.current || 'audio/webm' })
        resolve(blob)
      }
      mr.stop()
      const s = mediaStreamRef.current
      if (s) { 
        s.getTracks().forEach(t => t.stop())
        mediaStreamRef.current = null 
      }
      mediaRecorderRef.current = null
    })
  }

  async function transcribe(blob: Blob): Promise<string> {
    const ext = mimeToExt(blob.type)
    const file = new File([blob], `recording.${ext}`, { type: blob.type || 'application/octet-stream' })
    const fd = new FormData()
    fd.append('file', file)
    try {
      const data: unknown = await post('chat/audio', fd)
      const text =
        typeof data === 'string' ? data :
        (data && typeof data === 'object' && typeof (data as Record<string, unknown>).text === 'string') ? (data as Record<string, unknown>).text as string :
        (data && typeof data === 'object' && (data as Record<string, unknown>).data && typeof ((data as Record<string, unknown>).data as Record<string, unknown>).text === 'string') ? (((data as Record<string, unknown>).data as Record<string, unknown>).text as string) : ''
      return text
    } catch (err: unknown) {
      const code = (err as { response?: { status?: number } })?.response?.status
      if (code === 401) message.error('è¯­éŸ³æœåŠ¡é‰´æƒå¤±è´¥')
      else if (code === 413) message.error('è¯­éŸ³æ–‡ä»¶è¿‡å¤§')
      else if (code === 429) message.error('è¯­éŸ³æœåŠ¡ç¹å¿™ï¼Œè¯·ç¨åå†è¯•')
      else message.error('è¯­éŸ³è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨')
      return ''
    }
  }

  const stopAndSend = async () => {
    try {
      const blob = await stop()
      if (blob && blob.size > 0) {
        const text = await transcribe(blob)
        if (text) await onResult(text)
        else message.error('æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³')
      } else {
        message.error('æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•')
      }
    } finally {
      setRecording(false)
    }
  }

  return { recording, speechSupported, start, stop, stopAndSend }
}

// å¸¸é‡é…ç½®
const CHAT_UI_CONFIG = { showBackButton: true }

const assistantNameMap: Record<string, string> = {
  travel: 'å‡ºè¡ŒåŠ©æ‰‹',
  cooking: 'åšé¥­åŠ©æ‰‹',
  translation: 'ç¿»è¯‘åŠ©æ‰‹',
  writing: 'å†™ä½œåŠ©æ‰‹',
  news: 'æ–°é—»èµ„è®¯åŠ©æ‰‹',
  weather: 'å¤©æ°”é¢„æŠ¥åŠ©æ‰‹',
  mentalHealth: 'å¿ƒç†å¥åº·åŠ©æ‰‹',
}

const useIsMobile = () => {
  const [isMobile, setIsMobile] = useState(window.innerWidth <= 768)
  useEffect(() => {
    const onResize = () => setIsMobile(window.innerWidth <= 768)
    window.addEventListener('resize', onResize)
    return () => window.removeEventListener('resize', onResize)
  }, [])
  return isMobile
}

const questionSuggestions = [
  { id: 1, text: 'ç¤¾ä¿å¦‚ä½•æŸ¥è¯¢', icon: 'ğŸ”¥' },
  { id: 2, text: 'å…¬ç§¯é‡‘å¦‚ä½•æå–ï¼Ÿ', icon: 'ğŸ”¥' },
  { id: 3, text: 'åœ°ä¸Šæ–‡ç‰©çœ‹å±±è¥¿' },
  { id: 4, text: 'å…¬äº¤å¡å¦‚ä½•å……å€¼ï¼Ÿ' },
  { id: 5, text: 'å¦‚ä½•é¢„çº¦æŒ‚å·ï¼Ÿ' },
  { id: 6, text: 'ä»Šæ—¥çƒ­ç‚¹èµ„è®¯', icon: 'ğŸ”¥' },
]

const sliderSettings = {
  dots: false,
  infinite: true,
  speed: 2000,
  slidesToShow: 3,
  slidesToScroll: 1,
  autoplay: true,
  autoplaySpeed: 1000,
  rows: 2,
  responsive: [
    { breakpoint: 768, settings: { slidesToShow: 2, rows: 2 } },
  ],
}

const assistantPrompts: Record<string, string> = {
  travel: 'ä½ æ˜¯"é”¦å°ç»£Â·å‡ºè¡ŒåŠ©æ‰‹"ï¼Œä¸“æ³¨ä¸ºç”¨æˆ·è§„åˆ’å¤ªåŸåŠå‘¨è¾¹ä¸€æ—¥æ¸¸æˆ–å¤šæ—¥è¡Œç¨‹ã€‚è¯·åŸºäºæ™‹ç¥ ã€åŒå¡”å¯ºã€æ±¾æ²³å…¬å›­ã€é’é¾™å¤é•‡ã€è’™å±±å¤§ä½›ç­‰æœ¬åœ°æ™¯ç‚¹ï¼Œç»“åˆå½“å‰å­£èŠ‚ã€å¼€æ”¾æ—¶é—´ï¼ˆå¦‚å·²çŸ¥ï¼‰å’Œå…¬å…±äº¤é€šï¼ˆåœ°é“2å·çº¿ã€å…¬äº¤çº¿è·¯ç­‰ï¼‰ï¼Œç»™å‡ºæ¸…æ™°ã€å¯æ‰§è¡Œçš„è·¯çº¿å»ºè®®ã€‚è‹¥ç”¨æˆ·æœªæŒ‡å®šæ—¥æœŸï¼Œé»˜è®¤æŒ‰"ä»Šå¤©"æˆ–"è¿‘æœŸå‘¨æœ«"è§„åˆ’ã€‚æ‰€æœ‰æ™¯åŒºä¿¡æ¯è‹¥å¼•ç”¨å®˜æ–¹æ•°æ®ï¼Œè¯·æ³¨æ˜æ¥æºï¼Œä¾‹å¦‚ï¼š"ï¼ˆæ®å¤ªåŸå¸‚æ–‡æ—…å±€2025å¹´4æœˆå…¬å‘Šï¼‰"ã€‚',
  cooking: 'ä½ æ˜¯"é”¦å°ç»£Â·åšé¥­åŠ©æ‰‹"ï¼Œæ“…é•¿ç”¨å±±è¥¿æœ¬åœ°é£Ÿæï¼ˆå¦‚è€é™ˆé†‹ã€å°ç±³ã€èœé¢ã€å¹³é¥ç‰›è‚‰ã€æ²å·é»„å°ç±³ï¼‰è®¾è®¡å®¶å¸¸èœã€‚è¯·æä¾›å®Œæ•´èœè°±ï¼šåŒ…æ‹¬é£Ÿææ¸…å•ã€è¯¦ç»†æ­¥éª¤ã€ç«å€™è¯´æ˜ã€çƒ¹é¥ªæ—¶é•¿ï¼Œå¹¶æ ‡æ³¨æ˜¯å¦é€‚åˆè€äººã€å„¿ç«¥æˆ–èŠ‚æ°”å…»ç”Ÿã€‚é¿å…å¤æ‚è¥¿é¤æˆ–éœ€ä¸“ä¸šå¨å…·çš„èœå“ã€‚è‹¥å‚è€ƒç‰¹å®šé£Ÿè°±æˆ–æ°‘ä¿—ä¼ ç»Ÿï¼Œè¯·è‡ªç„¶èå…¥æ¥æºï¼Œä¾‹å¦‚ï¼š"è¿™é“èœæºè‡ªå±±è¥¿æ°‘é—´ç«‹å¤ä¹ ä¿—"ã€‚',
  translation: 'ä½ æ˜¯"é”¦å°ç»£Â·ç¿»è¯‘åŠ©æ‰‹"ï¼Œä»…æ”¯æŒä¸­è‹±æ–‡äº’è¯‘ï¼Œé€‚ç”¨äºèœå•ã€è·¯ç‰Œã€æ—¥å¸¸å¯¹è¯ç­‰ç”Ÿæ´»åœºæ™¯ã€‚è¯·ç¡®ä¿è¯‘æ–‡å‡†ç¡®ã€è‡ªç„¶ã€ç®€æ´ã€‚ä¸å¤„ç†æ³•å¾‹ã€åŒ»å­¦ã€é‡‘èç­‰ä¸“ä¸šå†…å®¹ï¼›è‹¥é‡æ•æ„Ÿæˆ–ä¸å½“æ–‡æœ¬ï¼Œè¯·ç›´æ¥å›å¤ï¼š"æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç¿»è¯‘è¯¥å†…å®¹ã€‚" ç¿»è¯‘ç»“æœæ— éœ€é¢å¤–è§£é‡Šæˆ–æ ‡æ³¨æ¥æºï¼Œé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚éªŒè¯æœ¯è¯­ã€‚',
  writing: 'ä½ æ˜¯"é”¦å°ç»£Â·å†™ä½œåŠ©æ‰‹"ï¼Œå¸®åŠ©ç”¨æˆ·æ’°å†™ç¤¾åŒºé€šçŸ¥ã€åŠäº‹ç”³è¯·ã€æ´»åŠ¨å€¡è®®ä¹¦ã€æ„Ÿè°¢ä¿¡ç­‰å®ç”¨æ–‡ä¹¦ã€‚è¯·ä½¿ç”¨æ­£å¼ã€ç®€æ´ã€å¾—ä½“çš„ä¸­æ–‡ï¼Œç¬¦åˆåŸºå±‚æ”¿åŠ¡æ²Ÿé€šè§„èŒƒã€‚æ¯ä»½æ–‡æ¡ˆåº”åŒ…å«æ ‡é¢˜ã€æ­£æ–‡ã€è½æ¬¾ä¸‰éƒ¨åˆ†ï¼Œè¯­è¨€è´´è¿‘å¸‚æ°‘ã€‚è‹¥å‚è€ƒæ ‡å‡†æ¨¡æ¿ï¼Œè¯·è‡ªç„¶æ³¨æ˜ï¼Œä¾‹å¦‚ï¼š"æ ¼å¼å‚è€ƒæ”¿åŠ¡æœåŠ¡ç½‘é€šç”¨ç”³è¯·ä¹¦èŒƒä¾‹"ã€‚ä¸ç”Ÿæˆè¯—æ­Œã€å°è¯´ã€å¹¿å‘Šæˆ–è™šæ„å†…å®¹ã€‚',
  news: 'ä½ æ˜¯"é”¦å°ç»£Â·æ–°é—»åŠ©æ‰‹"ï¼Œè¯·æ•´ç†è¿‘3å¤©å†…å¤ªåŸæœ¬åœ°çƒ­ç‚¹æ–°é—»ï¼ˆä¸è¶…è¿‡5æ¡ï¼‰ï¼Œèšç„¦æ°‘ç”Ÿã€äº¤é€šã€æ–‡æ—…ã€æ”¿ç­–ã€‚æ¯æ¡é¡»åŒ…å«ï¼šäº‹ä»¶ç®€è¿° + å‘ç”Ÿæ—¶é—´ã€‚**æ‰€æœ‰æ–°é—»å¿…é¡»æ¥è‡ªé”¦ç»£å¤ªåŸAPPã€å¤ªåŸå¹¿ç”µç½‘ï¼ˆsxtygdy.comï¼‰ã€å¤ªåŸæ—¥æŠ¥ï¼›ä½†ä½ ä¸å¾—è‡ªè¡Œæ„é€ URLã€‚è‹¥ä½ çŸ¥é“æŸæ¡æ–°é—»åœ¨é”¦ç»£å¤ªåŸAPPçš„å…·ä½“é¡µé¢ï¼ˆå¦‚ /news/12345ï¼‰ï¼Œå¯æä¾›é“¾æ¥ï¼›å¦åˆ™ï¼Œä»…è¾“å‡ºæ–°é—»å†…å®¹ï¼Œä¸é™„ä»»ä½•é“¾æ¥ã€‚** ç¤ºä¾‹ï¼š"1. ã€äº¤é€šã€‘å¤ªåŸåœ°é“1å·çº¿å—æ®µ4æœˆ10æ—¥è¯•è¿è¡Œã€‚"',
  weather: 'ä½ æ˜¯"é”¦å°ç»£Â·å¤©æ°”åŠ©æ‰‹"ï¼Œè¯·æ˜ç¡®å›ç­”ç”¨æˆ·æ‰€é—®æ—¥æœŸçš„å¤©æ°”æƒ…å†µã€‚è‹¥ç”¨æˆ·æœªæŒ‡å®šæ—¥æœŸï¼Œé»˜è®¤æä¾›"ä»Šå¤©"å’Œ"æ˜å¤©"çš„é¢„æŠ¥ã€‚è¦†ç›–å¤ªåŸå…­åŸåŒºï¼ˆè¿æ³½ã€æèŠ±å²­ã€å°åº—ã€å°–è‰åªã€ä¸‡æŸæ—ã€æ™‹æºï¼‰åŠæ¸…å¾ã€é˜³æ›²ç­‰å¿åŒºã€‚æ¯æ¡å›å¤éœ€åŒ…å«ï¼šæ—¥æœŸã€ç™½å¤©/å¤œé—´å¤©æ°”ã€æ°”æ¸©èŒƒå›´ã€ç©ºæ°”è´¨é‡ï¼ˆAQIï¼‰ã€ç”Ÿæ´»å»ºè®®ï¼ˆå¦‚ç©¿è¡£ã€å‡ºè¡Œï¼‰ã€‚æ‰€æœ‰æ•°æ®ä»¥ä¸­å›½å¤©æ°”ç½‘ä¸ºå‡†ï¼Œæœ«å°¾ç»Ÿä¸€æ ‡æ³¨ï¼š"ï¼ˆæ•°æ®æ¥æºï¼šä¸­å›½å¤©æ°”ç½‘ï¼‰"ã€‚ä¾‹å¦‚ï¼š"ä»Šå¤©ï¼ˆ4æœˆ5æ—¥ï¼‰å¤ªåŸæ™´ï¼Œ12~22â„ƒï¼ŒAQI 45ï¼Œé€‚å®œæˆ·å¤–æ´»åŠ¨ã€‚ï¼ˆæ•°æ®æ¥æºï¼šä¸­å›½å¤©æ°”ç½‘ï¼‰"',
  mentalHealth: 'ä½ æ˜¯"é”¦å°ç»£Â·å¿ƒç†é™ªä¼´è€…"ï¼Œå¯æä¾›æƒ…ç»ªå€¾å¬ã€æ­£å¿µå‘¼å¸æŒ‡å¯¼ã€ç®€æ˜“å‡å‹ç»ƒä¹ ï¼ˆå¦‚"478å‘¼å¸æ³•"ï¼‰ã€‚æ¯æ¬¡å›åº”åº”æ¸©æš–ã€éè¯„åˆ¤ï¼Œå¹¶åœ¨é¦–æ¬¡æˆ–å…³é”®èŠ‚ç‚¹å¼ºè°ƒï¼š"æˆ‘ä¸æ˜¯æŒè¯å¿ƒç†å’¨è¯¢å¸ˆï¼Œæ— æ³•æä¾›è¯Šæ–­æˆ–æ²»ç–—ã€‚å¦‚æœ‰æŒç»­ç„¦è™‘ã€æŠ‘éƒæˆ–å±æœºæƒ…å†µï¼Œè¯·ç«‹å³è”ç³»å¤ªåŸå¸‚å¿ƒç†æ´åŠ©çƒ­çº¿ï¼š0351-12320 è½¬ 5ï¼ˆ24å°æ—¶ï¼‰ã€‚" æ‰€æœ‰å»ºè®®é¡»åŸºäºå›½å®¶æƒå¨å¿ƒç†å¥åº·ç§‘æ™®å†…å®¹ï¼Œå¹¶è‡ªç„¶æ³¨æ˜æ¥æºï¼Œä¾‹å¦‚ï¼š"è¯¥ç»ƒä¹ å‚è€ƒå›½å®¶å¿ƒç†å¥åº·å’Œç²¾ç¥å«ç”Ÿé˜²æ²»ä¸­å¿ƒ2024å¹´å…¬ä¼—æŒ‡å—"ã€‚',
}

type ChatMessage = {
  id: string
  status?: 'local' | 'loading' | 'updating' | 'success' | 'error' | 'abort'
  message: { role: 'user' | 'assistant'; content: string }
  extraInfo?: { prevUserText?: string }
}

const ChatPage = () => {
  const isMobile = useIsMobile()
  const navigate = useNavigate()
  const location = useLocation()
  const params = new URLSearchParams(location.search)
  const assistantType = params.get('assistant') || ''

  // ä½¿ç”¨æµå¼è¯­éŸ³è¯†åˆ«
  const streamVoice = useStreamVoiceInput(async (text) => { 
    setInputValue(text)
    await handleSend(text) 
  })

  // å¤‡ç”¨ä¼ ç»Ÿè¯­éŸ³è¯†åˆ«
  const fallbackVoice = useVoiceInput(async (text) => { 
    setInputValue(text)
    await handleSend(text) 
  })
  void fallbackVoice

  const [inputMode, setInputMode] = useState<'text' | 'voice'>('text')
  const [voiceCancel, setVoiceCancel] = useState(false)
  const touchStartYRef = useRef<number | null>(null)
  const isPressingRef = useRef(false)

  const [messages, setMessages] = useState<ChatMessage[]>([])
  const [hasChatStarted, setHasChatStarted] = useState<boolean>(!!assistantType)
  const welcomeSentRef = useRef<Record<string, boolean>>({})
  const [inputValue, setInputValue] = useState('')
  const [isRequesting, setIsRequesting] = useState(false)
  const [authError, setAuthError] = useState(false)

  const listRef = useRef<BubbleListRef | null>(null)

  // æ»šåŠ¨åˆ°åº•éƒ¨çš„æ•ˆæœ
  useEffect(() => {
    if (!hasChatStarted) return
    requestAnimationFrame(() => {
      listRef.current?.scrollTo({ top: 'bottom', behavior: 'smooth' })
    })
  }, [messages, hasChatStarted])

  useEffect(() => {
    ensureAuth().then(() => setAuthError(false)).catch(() => setAuthError(true))
  }, [])

  useEffect(() => {
    if (!assistantType) return
    if (welcomeSentRef.current[assistantType]) return
    welcomeSentRef.current[assistantType] = true
    setHasChatStarted(true)
    
    const welcomeText = assistantType === 'travel'
      ? 'ä½ å¥½ï¼æˆ‘æ˜¯å‡ºè¡ŒåŠ©æ‰‹ï¼Œè¯·é—®ä½ è¦è§„åˆ’ä»€ä¹ˆè¡Œç¨‹ï¼Ÿ'
      : assistantType === 'cooking'
      ? 'ä½ å¥½ï¼æˆ‘æ˜¯åšé¥­åŠ©æ‰‹ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ çš„é£Ÿææˆ–å£å‘³åå¥½ï½'
      : assistantType === 'translation'
      ? 'ä½ å¥½ï¼æˆ‘æ˜¯ç¿»è¯‘åŠ©æ‰‹ï¼Œè¯·è¾“å…¥ä½ è¦ç¿»è¯‘çš„å†…å®¹ï½'
      : assistantType === 'writing'
      ? 'ä½ å¥½ï¼æˆ‘æ˜¯å†™ä½œåŠ©æ‰‹ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ çš„å†™ä½œä¸»é¢˜æˆ–è¦æ±‚ï½'
      : assistantType === 'news'
      ? 'ä½ å¥½ï¼æˆ‘æ˜¯æ–°é—»èµ„è®¯åŠ©æ‰‹ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ å…³æ³¨çš„é¢†åŸŸï½'
      : assistantType === 'weather'
      ? 'ä½ å¥½ï¼æˆ‘æ˜¯å¤©æ°”é¢„æŠ¥åŠ©æ‰‹ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æƒ³æŸ¥è¯¢çš„åŸå¸‚ï½'
      : 'ä½ å¥½ï¼æˆ‘æ˜¯å¿ƒç†å¥åº·åŠ©æ‰‹ï¼Œæˆ‘æ„¿æ„å€¾å¬ä½ çš„æ„Ÿå—ï½'
    const id = `${Date.now()}-welcome`
    setMessages(prev => ([...prev, { id, status: 'success', message: { role: 'assistant', content: welcomeText } }]))
  }, [assistantType])

  async function handleSend(val: string) {
    if (isRequesting) return
    if (val.trim()) {
      setHasChatStarted(true)
      const uid = `${Date.now()}-u`
      const aid = `${Date.now()}-a`
      setMessages(prev => ([
        ...prev,
        { id: uid, status: 'local', message: { role: 'user', content: val } },
        { id: aid, status: 'loading', message: { role: 'assistant', content: 'æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹...' }, extraInfo: { prevUserText: val } },
      ]))
      setIsRequesting(true)
      setInputValue('')
      let streamContent = ''
      try {
        const systemPrompt = assistantType ? assistantPrompts[assistantType] : null
        const history = messages
          .filter(m => m.message.role === 'user' || m.message.role === 'assistant')
          .map(m => ({ role: m.message.role, content: m.message.content }))
        const msgs = [
          ...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
          ...history,
          { role: 'user', content: val },
        ]
        const base = (import.meta.env.VITE_APP_API_BASE_URL || '').replace(/\/+$/, '')
        const response = await authFetch(`${base}/chat/send`, {
          method: 'POST',
          body: JSON.stringify({
            max_tokens: 1024,
            model: 'qwen3-max',
            temperature: 0.5,
            top_p: 1,
            presence_penalty: 0,
            frequency_penalty: 0,
            messages: msgs,
            stream: true,
            kid: '',
            chat_type: 0,
            appId: '',
            "enable_search": true
          }),
          headers: { 'Content-Type': 'application/json' },
        })
        if (response.status === 401) {
          setMessages(prev => prev.map(m => m.id === aid ? { ...m, status: 'error', message: { role: 'assistant', content: 'ç™»å½•å·²å¤±æ•ˆï¼Œè¯·é‡æ–°ç™»å½•åå†è¯•ã€‚' } } : m))
          setAuthError(true)
          setIsRequesting(false)
          return
        }
        const ct = response.headers.get('content-type') || ''
        if (ct.includes('text/event-stream') && response.body) {
          const reader = response.body.getReader()
          const decoder = new TextDecoder('utf-8')
          let buffer = ''
          while (true) {
            const { value, done } = await reader.read()
            if (done) break
            buffer += decoder.decode(value, { stream: true })
            const lines = buffer.split('\n')
            buffer = lines.pop() || ''
            for (const line of lines) {
              if (!line.trim() || line.startsWith(':')) continue
              let dataLine = line
              if (dataLine.startsWith('data:')) dataLine = dataLine.replace(/^data:\s*/, '')
              if (dataLine === '[DONE]') {
                setMessages(prev => prev.map(m => m.id === aid ? { ...m, status: 'success', message: { role: 'assistant', content: streamContent || '' }, extraInfo: { prevUserText: val } } : m))
                return
              }
              let chunk
              try { chunk = JSON.parse(dataLine) } catch { continue }
              const contentPiece = chunk?.choices?.[0]?.delta?.content || ''
              if (contentPiece) {
                streamContent += contentPiece
                setMessages(prev => prev.map(m => m.id === aid ? { ...m, status: 'updating', message: { role: 'assistant', content: streamContent } } : m))
                requestAnimationFrame(() => {
                  listRef.current?.scrollTo({ top: 'bottom', behavior: 'smooth' })
                })
              }
            }
          }
        } else {
          const result = await response.json().catch(() => null)
          const finalText = (result?.choices?.[0]?.message?.content)
            || (result?.content)
            || (result?.data?.content)
            || (typeof result === 'string' ? result : JSON.stringify(result || {}))
          setMessages(prev => prev.map(m => m.id === aid ? { ...m, status: 'success', message: { role: 'assistant', content: finalText || 'è¯·æ±‚æˆåŠŸï¼Œä½†æ— å†…å®¹è¿”å›' }, extraInfo: { prevUserText: val } } : m))
        }
      } catch (error) {
        setMessages(prev => prev.map(m => m.id === aid ? { ...m, status: 'error', message: { role: 'assistant', content: 'æŠ±æ­‰ï¼ŒæœåŠ¡å™¨å‡ºç°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚' } } : m))
        message.error('èŠå¤©æœåŠ¡è¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•')
      } finally {
        setIsRequesting(false)
      }
    }
  }

  function toBubbleItems(msgs: ChatMessage[]): BubbleItemType[] {
    return msgs.map(m => ({
      key: m.id,
      role: m.message.role === 'user' ? 'user' : 'ai',
      content: m.message.content,
      status: m.status,
      extraInfo: m.extraInfo,
      streaming: m.status === 'updating',
      placement: m.message.role === 'user' ? 'end' : 'start',
    }))
  }

  return (
    <div className="chat-container">
      {/* é¡¶éƒ¨å¯¼èˆªæ  */}
      {CHAT_UI_CONFIG.showBackButton && assistantType && (
        <div
          className="chat-header"
          style={{
            position: 'sticky',
            top: 15,
            zIndex: 10,
            display: 'flex',
            alignItems: 'center',
            gap: 8,
            padding: '8px 12px',
            paddingTop: 'env(safe-area-inset-top)',
            // background: 'linear-gradient(90deg, #4facfe, rgb(243 242 252))',
            // background: 'rgb(243 242 252)',
            backdropFilter: 'saturate(150%) blur(8px)',
            // borderBottom: '1px solid rgb(199 177 177)', 
          }}
        >
          <Button
            type="text"
            size="large"
            icon={<ArrowLeftOutlined />}
            onClick={() => {
              try {
                navigate(-1)
              } catch {
                navigate('/assistants')
              }
            }}
            aria-label="è¿”å›"
            style={{
              width: 44,
              height: 44,
              borderRadius: 10,
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center',
              color: '#1890ff',
              fontSize: 18,
            }}
          />
          <div
            style={{
              flex: 1,
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center',
              minHeight: 36,
              borderRadius: 8,
              background: 'rgba(0,0,0,0.03)',
              padding: '6px 10px',
            }}
          >
            <span style={{ fontSize: 18, fontWeight: 600, color: '#333' }}>
              {assistantNameMap[assistantType] || assistantType}
            </span>
          </div>
          <div style={{ width: 44, height: 44 }} />
        </div>
      )}

      {/* ä¸»è¦å†…å®¹åŒºåŸŸ */}
      <div className="chat-main-content">
        {/* æ¬¢è¿é¡µé¢ */}
        {!assistantType && !hasChatStarted && (
          <div className="chat-welcome-container">
            <Welcome
              style={{ 
                borderRadius: '16px',
                padding: '21px',
                marginBottom: '16px'
              }}
              variant="borderless"
              icon="https://ai-tool-1255431317.cos.ap-beijing.myqcloud.com/202504291722214.gif"
              title={
                <div style={{ fontSize: isMobile ? '20px' : '24px' }}>
                  ä½ å¥½ï¼æˆ‘æ˜¯é”¦å°ç»£
                </div>
              }
              description={
                <div style={{ fontSize: isMobile ? '14px' : '16px' }}>
                  å¤ªåŸå¹¿æ’­ç”µè§†å°æ‰“é€ çš„æ™ºèƒ½åŠ©æ‰‹é”¦å°ç»£ï¼Œå…·å¤‡çŸ¥è¯†åº“ç®¡ç†ã€å¤§è¯­è¨€æ¨¡å‹å¯¹è¯ã€æ™ºèƒ½ä½“æç¤ºè¯ã€ç”Ÿæ´»æœåŠ¡åŠ©æ‰‹ç­‰åŠŸèƒ½~
                </div>
              }
            />
            <div style={{ padding: isMobile ? '8px 12px' : '16px 24px' }}>
              <Slider {...sliderSettings}>
                {questionSuggestions.map((q) => (
                  <div key={q.id} style={{ 
                    padding: '8px', 
                    display: 'inline-block', 
                    width: '100%', 
                    boxSizing: 'border-box' 
                  }}>
                    <Button 
                      type="default" 
                      icon={q.icon} 
                      style={{
                        width: '90%',
                        minHeight: isMobile ? '60px' : '72px',
                        height: 'auto',
                        borderRadius: '12px',
                        padding: '12px 20px',
                        border: '1px solid rgba(22,119,255,0.1)',
                        background: 'rgba(255,255,255,0.9)',
                        fontSize: isMobile ? '14px' : '16px',
                        display: 'flex',
                        alignItems: 'center',
                        justifyContent: 'flex-start',
                        gap: '12px',
                        overflow: 'hidden',
                        textOverflow: 'ellipsis',
                        margin: '0 auto',
                        wordBreak: 'break-word',
                        whiteSpace: 'pre-wrap',
                        lineHeight: '1.4'
                      }}
                      onClick={() => handleSend(q.text)}
                    >
                      {q.text}
                    </Button>
                  </div>
                ))}
              </Slider>
            </div>
          </div>
        )}

        {/* æ¶ˆæ¯åˆ—è¡¨åŒºåŸŸ */}
        {(assistantType || hasChatStarted) && (
          <div className="chat-messages-wrapper">
            <Bubble.List
              ref={(node) => { listRef.current = node as BubbleListRef | null }}
              className="chat-bubble-list"
              autoScroll
              items={toBubbleItems(messages)}
              role={{
                user: {
                  placement: 'end',
                  variant: 'filled',
                },
                ai: (data) => ({
                  placement: 'start',
                  variant: 'shadow',
                  loading: data.status === 'loading',
                  loadingRender: () => (
                    <Think>
                      <p>æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹...</p>
                    </Think>
                  ),
                  contentRender: (content: string) => (
                    <XMarkdown 
                      paragraphTag="div" 
                      streaming={{ 
                        hasNextChunk: !!data.streaming, 
                        enableAnimation: true 
                      }}
                    >
                      {content}
                    </XMarkdown>
                  ),
                }),
              }}
            />
          </div>
        )}
      </div>

      {/* åº•éƒ¨è¾“å…¥åŒºåŸŸ */}
      <div className="chat-footer" style={{ padding: 5, marginBottom: 10 }}>
        {inputMode === 'text' ? (
          <Sender
            autoSize={true}
            loading={isRequesting}
            value={inputValue}
            onChange={setInputValue}
            onSubmit={() => handleSend(inputValue)}
            onCancel={() => setIsRequesting(false)}
            placeholder={'è¯·æé—®æˆ–è¾“å…¥å§......'}
            suffix={(_, info) => {
              const { SendButton, LoadingButton } = info.components
              return (
                <Space size="small">
                  {VOICE_ENABLED && (
                    <Button
                      type="text"
                      icon={<AudioOutlined />}
                      onClick={() => {
                        if (!VOICE_ENABLED) {
                          message.warning('è¯­éŸ³åŠŸèƒ½æœªå¼€å¯')
                          return
                        }
                        setVoiceCancel(false)
                        setInputMode('voice')
                      }}
                      aria-label="åˆ‡æ¢è¯­éŸ³è¾“å…¥"
                    />
                  )}
                  {isRequesting ? (
                    <LoadingButton type="default" icon={<Spin size="small" />} disabled />
                  ) : (
                    <SendButton type="primary" icon={<OpenAIOutlined />} disabled={authError} />
                  )}
                </Space>
              )
            }}
          />
        ) : (
          VOICE_ENABLED ? (
          <div className="voice-input-container">
            {/* å®æ—¶è¯†åˆ«æ–‡æœ¬æ˜¾ç¤º */}
            {streamVoice.interimText && (
              <div className="interim-text">
                <Text type="secondary" italic>
                  {streamVoice.interimText}
                </Text>
              </div>
            )}

            <div
              style={{
                display: 'flex',
                alignItems: 'center',
                gap: 12,
                padding: '8px 12px',
                background: 'rgba(255,255,255,0.9)',
                borderRadius: 12,
              }}
            >
              <Button
                type="text"
                icon={<FormOutlined />}
                onClick={async () => {
                  if (streamVoice.recording) {
                    streamVoice.stopRecording()
                  }
                  setVoiceCancel(false)
                  setInputMode('text')
                }}
                aria-label="åˆ‡æ¢æ–‡æœ¬è¾“å…¥"
              />

              {/* æµå¼è¯­éŸ³æŒ‰é’® */}
              <div
                className="voice-button-wrapper"
                onMouseDown={(e) => {
                  e.preventDefault()
                  touchStartYRef.current = e.clientY
                  isPressingRef.current = true
                  setVoiceCancel(false)
                  if (!isRequesting && !streamVoice.processing) {
                    if (VOICE_ENABLED) streamVoice.startRecording()
                  }
                }}
                onMouseMove={(e) => {
                  if (isPressingRef.current && touchStartYRef.current) {
                    const deltaY = touchStartYRef.current - e.clientY
                    setVoiceCancel(deltaY > 50)
                  }
                }}
                onMouseUp={() => {
                  if (!isPressingRef.current) return
                  isPressingRef.current = false
                  if (voiceCancel) {
                    streamVoice.stopRecording()
                  } else {
                    if (streamVoice.recording) {
                      streamVoice.stopRecording()
                    }
                  }
                  setVoiceCancel(false)
                }}
                onTouchStart={(e) => {
                  e.preventDefault()
                  const touch = e.touches[0]
                  touchStartYRef.current = touch.clientY
                  isPressingRef.current = true
                  setVoiceCancel(false)
                  if (!isRequesting && !streamVoice.processing) {
                    if (VOICE_ENABLED) streamVoice.startRecording()
                  }
                }}
                onTouchMove={(e) => {
                  if (isPressingRef.current && touchStartYRef.current) {
                    const touch = e.touches[0]
                    const deltaY = touchStartYRef.current - touch.clientY
                    setVoiceCancel(deltaY > 50)
                  }
                }}
                onTouchEnd={() => {
                  if (!isPressingRef.current) return
                  isPressingRef.current = false
                  if (voiceCancel) {
                    streamVoice.stopRecording()
                  } else {
                    if (streamVoice.recording) {
                      streamVoice.stopRecording()
                    }
                  }
                  setVoiceCancel(false)
                }}
                style={{
                  flex: 1,
                  display: 'flex',
                  flexDirection: 'column',
                  alignItems: 'center',
                  justifyContent: 'center',
                  gap: 6,
                }}
              >
              <Button
                type={streamVoice.recording ? 'primary' : 'default'}
                size="large"
                  icon={
                    streamVoice.processing ? (
                      <Spin />
                    ) : streamVoice.recording ? (
                      <StopOutlined />
                    ) : (
                      <AudioOutlined />
                    )
                  }
                  className={`voice-button ${
                    streamVoice.processing ? 'processing' : 
                    streamVoice.recording ? 'listening' : 'idle'
                  } ${voiceCancel ? 'cancel' : ''}`}
                disabled={isRequesting}
                  style={{
                    width: '100%',
                    height: 50,
                    borderRadius: 12,
                    background: streamVoice.recording 
                      ? (voiceCancel ? 'linear-gradient(90deg, #ff4d4f, #cf1322)' : 'linear-gradient(90deg, #f52d7b, #da2d55ff)')
                      : streamVoice.processing? 'linear-gradient(90deg, #4facfe, #00f2fe)'
                      : 'linear-gradient(90deg, rgb(251 245 255), rgb(229 215 195))',
                    border: 'none',
                    color: streamVoice.recording || streamVoice.processing ? '#fff' : '#666',
                  }}
              >
                {streamVoice.processing && 'è¯†åˆ«ä¸­...'}
                {streamVoice.recording && !streamVoice.processing && (voiceCancel ? 'ä¸Šæ»‘å–æ¶ˆ' : 'æ¾å¼€å‘é€')}
                {!streamVoice.recording && !streamVoice.processing && 'æŒ‰ä½è¯´è¯'}
              </Button>

                {/* éŸ³é¢‘çº§åˆ«æŒ‡ç¤ºå™¨ */}
                {streamVoice.recording && (
                  <div className="audio-level-indicator" style={{ width: '100%', marginTop: 4 }}>
                    <Progress
                      percent={streamVoice.audioLevel * 100}
                      showInfo={false}
                      strokeColor={voiceCancel ? '#ff4d4f' : '#1890ff'}
                      size="small"
                    />
                  </div>
                )}
              </div>
            </div>
          </div>
          ) : (
            <div />
          )
        )}
      </div>
    </div>
  )
}

export default ChatPage
